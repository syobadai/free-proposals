 
### The management of OS images such as those used in virtual machines using diff by git.
* Assuming that each OS image file is at least several tens of GB or more.

#### Background
* I tried to "git push" a 60GB Windows OS image directly with local git, but it took a long time to git-add and git-push(dozens of minutes on an old PC).
* "out of memory by malloc" occurred when not via "git-lfs", and I tried "git-repack" to deal with this, but I could not solve it.
* When I searched for a solution with common tools and commands, I found the method "split the OS image using the 'split' command of Linux and manage the diff of these obtained files by git".

* This method can shorten the push time and eliminate the out of memory by adjusting the size of the division, but 1) it is wasteful in terms of capacity and 2) inconvenient in terms of practical use.
	1) Capacity: The amount of data to be retained is doubled at the maximum per OS image ("Original that must be loaded into the virtual machine" + "Divided files tracked by GIT"). This will increase even more if the GIT repository is included.
	2) Reintegration / Redivision: When running a target OS image in a virtual machine, the files generated by the division must be reintegrated into a single bootable OS image. it also must be redivided again　when storing.

* Below, a proposal to eliminate these two inconveniences by using "technology like symbolic links"

#### +++++++++++++++ START PROPOSAL +++++++++++++++++

* If symbolic links can be used arbitrarily distributed for one file, the above waste can be eliminated.
	* Subdivide a huge file and refer to each element like a symbolic link
	* Set git so that a behavior of symbolic links (which are often seen in applications like IDEs, they are treated as if they were real files even though they are links) is done when "git push"(I'm not familiar with git.I've seen it work like this without doing anything between Windows-GitHub).
	* After that, exclude the original OS image file from the tracking by git (= only the divided files is tracked).
	* For cloning, prepare a helper function to reintegrate the divided files.

* With these, the waste mentioned above 1),2) can be omitted. the management of OS image using diff by git is performed at a relatively high speed without suffering from reintegration / subdivision.
	1) The capacity held at the clone destination is "the capacity of the image disk" + "the number of divisions x the size of the symbolic link file" per OS image, and the GIT repository is added to this.
	2) Since the original OS image always keeps its original shape, it is not necessary to repeat the above-mentioned reintegration and subdivision. Regarding the generation of the prototype, the helper function only automatically reintegrates the divided files at the time of cloning.

* By eliminating the repeating structure of the OS, it is possible to significantly reduce the capacity and easily switch the state without creating a user.
In addition, the more repeating structures, the less the total capacity of transferring when transferring OS images to other environments (savings in virtual machine-based development environments).
Conventional management and debugging by git can also be used.

#### +++++++++++++++ END PROPOSAL +++++++++++++++++


* I decided that I could not implement　at least  the "technology like symbolic link" part in a short period of time, so I kept it as a proposal.
* Althogh I call it this way because I don't know the name of the technology, "Technology like symbolic links" may already exist. 
In a programming language, There is a function of specifying an offset for a certain file and trying to lock the file in a specific section. So if there is no difference between the folder and the file at the hard disk level,
I thought that the expression like the symbolic link in the relationship of "folder - file"  could be possible even in the relationship of "a file-a group of dividing elements of that file" by using the file name and offset.

 
 
 
